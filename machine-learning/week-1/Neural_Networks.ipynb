{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b57a946-4de9-4556-a2cc-a6964b0ef7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a0b605-651d-4ea6-92e4-b20fae344c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "493bf52d-8f5f-4d15-81a9-1b676a3ec4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8081454d-8783-4ae5-bae1-51e60fc2f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "defc293a-8f32-4fc5-9961-917fd89f9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('training_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "674feaea-a801-4514-a766-a41561568ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop('output', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8060d8f-698a-4d1c-9efd-b822f0f69bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11ad3f88-5fc7-4aca-8988-b0583a7e2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01ec509c-bb61-4a6e-9f6c-c0724036b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('testing_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d2e81862-4b69-4d90-ad04-027756cd640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop('output', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0202393f-5c84-40ff-9053-74448cfd741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c121e-c769-47cf-bba5-c8fb2c750b1a",
   "metadata": {},
   "source": [
    "# Model Using Partial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db26d51a-3e34-44ef-b51e-14dc878569ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled class distribution: Counter({0: 7506, 1: 7506})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_under_train, y_under_train = undersample.fit_resample(X_train, y_train)\n",
    "print(\"Undersampled class distribution:\", Counter(y_under_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1eea1576-f55b-4805-a445-6a3286aeb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "791a9852-88da-43c5-97c7-bef15321a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(26, activation = 'relu'))\n",
    "model.add(Dense(14, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7669b6d0-cfb6-41a8-b8d3-8a8a9d9e8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed8fb3d6-2104-4db2-8f07-7383e0c18f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 9362.8525 - val_loss: 17200.0098\n",
      "Epoch 2/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 8182.5142 - val_loss: 14824.4111\n",
      "Epoch 3/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 7085.9995 - val_loss: 12503.8398\n",
      "Epoch 4/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 5965.5293 - val_loss: 10252.6895\n",
      "Epoch 5/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 4809.8174 - val_loss: 8073.1172\n",
      "Epoch 6/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3707.2798 - val_loss: 6321.4062\n",
      "Epoch 7/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3050.1096 - val_loss: 4786.2925\n",
      "Epoch 8/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 2180.0610 - val_loss: 3523.2095\n",
      "Epoch 9/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1574.9531 - val_loss: 2291.1233\n",
      "Epoch 10/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1012.1505 - val_loss: 1642.4404\n",
      "Epoch 11/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 766.9150 - val_loss: 1280.2360\n",
      "Epoch 12/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 591.9662 - val_loss: 948.2571\n",
      "Epoch 13/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 423.4669 - val_loss: 640.7453\n",
      "Epoch 14/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 286.9396 - val_loss: 347.8344\n",
      "Epoch 15/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 145.5753 - val_loss: 72.4913\n",
      "Epoch 16/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 16.6545 - val_loss: 1.5821\n",
      "Epoch 17/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.9779 - val_loss: 0.8665\n",
      "Epoch 18/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.7350 - val_loss: 0.7027\n",
      "Epoch 19/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6716 - val_loss: 0.6974\n",
      "Epoch 20/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6666 - val_loss: 0.6971\n",
      "Epoch 21/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6646 - val_loss: 0.6971\n",
      "Epoch 22/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6682 - val_loss: 0.6970\n",
      "Epoch 23/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6691 - val_loss: 0.6972\n",
      "Epoch 24/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6652 - val_loss: 0.6973\n",
      "Epoch 25/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6660 - val_loss: 0.6975\n",
      "Epoch 26/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6634 - val_loss: 0.6977\n",
      "Epoch 27/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6649 - val_loss: 0.6979\n",
      "Epoch 28/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6613 - val_loss: 0.6982\n",
      "Epoch 29/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6686 - val_loss: 0.6985\n",
      "Epoch 30/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6636 - val_loss: 0.6989\n",
      "Epoch 31/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6592 - val_loss: 0.6995\n",
      "Epoch 32/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6590 - val_loss: 0.7001\n",
      "Epoch 33/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6608 - val_loss: 0.7006\n",
      "Epoch 34/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6585 - val_loss: 0.7013\n",
      "Epoch 35/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6616 - val_loss: 0.7022\n",
      "Epoch 36/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6554 - val_loss: 0.7032\n",
      "Epoch 37/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6552 - val_loss: 0.7041\n",
      "Epoch 38/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6557 - val_loss: 0.7051\n",
      "Epoch 39/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6529 - val_loss: 0.7062\n",
      "Epoch 40/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6563 - val_loss: 0.7074\n",
      "Epoch 41/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6519 - val_loss: 0.7090\n",
      "Epoch 42/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6517 - val_loss: 0.7111\n",
      "Epoch 43/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6549 - val_loss: 0.7137\n",
      "Epoch 44/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6499 - val_loss: 0.7171\n",
      "Epoch 45/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.6479 - val_loss: 0.7213\n",
      "Epoch 46/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6366 - val_loss: 0.7266\n",
      "Epoch 47/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6394 - val_loss: 0.7328\n",
      "Epoch 48/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6369 - val_loss: 0.7404\n",
      "Epoch 49/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6306 - val_loss: 0.7490\n",
      "Epoch 50/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6278 - val_loss: 0.7581\n",
      "Epoch 51/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6252 - val_loss: 0.7651\n",
      "Epoch 52/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6194 - val_loss: 0.7686\n",
      "Epoch 53/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6247 - val_loss: 0.7674\n",
      "Epoch 54/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6230 - val_loss: 0.7646\n",
      "Epoch 55/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6217 - val_loss: 0.7601\n",
      "Epoch 56/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6125 - val_loss: 0.7565\n",
      "Epoch 57/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6167 - val_loss: 0.7538\n",
      "Epoch 58/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6223 - val_loss: 0.7522\n",
      "Epoch 59/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6140 - val_loss: 0.7516\n",
      "Epoch 60/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6176 - val_loss: 0.7515\n",
      "Epoch 61/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6131 - val_loss: 0.7513\n",
      "Epoch 62/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6190 - val_loss: 0.7511\n",
      "Epoch 63/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6211 - val_loss: 0.7507\n",
      "Epoch 64/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6156 - val_loss: 0.7505\n",
      "Epoch 65/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6139 - val_loss: 0.7499\n",
      "Epoch 66/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6194 - val_loss: 0.7486\n",
      "Epoch 67/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6191 - val_loss: 0.7469\n",
      "Epoch 68/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6136 - val_loss: 0.7454\n",
      "Epoch 69/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.6102 - val_loss: 0.7442\n",
      "Epoch 70/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6100 - val_loss: 0.7433\n",
      "Epoch 71/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6093 - val_loss: 0.7424\n",
      "Epoch 72/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6082 - val_loss: 0.7416\n",
      "Epoch 73/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6128 - val_loss: 0.7403\n",
      "Epoch 74/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6067 - val_loss: 0.7396\n",
      "Epoch 75/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6116 - val_loss: 0.7376\n",
      "Epoch 76/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6132 - val_loss: 0.7361\n",
      "Epoch 77/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6076 - val_loss: 0.7345\n",
      "Epoch 78/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6079 - val_loss: 0.7331\n",
      "Epoch 79/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6096 - val_loss: 0.7317\n",
      "Epoch 80/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6087 - val_loss: 0.7304\n",
      "Epoch 81/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6076 - val_loss: 0.7293\n",
      "Epoch 82/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6074 - val_loss: 0.7277\n",
      "Epoch 83/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6096 - val_loss: 0.7267\n",
      "Epoch 84/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6085 - val_loss: 0.7260\n",
      "Epoch 85/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6050 - val_loss: 0.7251\n",
      "Epoch 86/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6099 - val_loss: 0.7236\n",
      "Epoch 87/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6049 - val_loss: 0.7224\n",
      "Epoch 88/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6099 - val_loss: 0.7203\n",
      "Epoch 89/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6034 - val_loss: 0.7186\n",
      "Epoch 90/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6072 - val_loss: 0.7170\n",
      "Epoch 91/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6054 - val_loss: 0.7153\n",
      "Epoch 92/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6010 - val_loss: 0.7142\n",
      "Epoch 93/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6075 - val_loss: 0.7124\n",
      "Epoch 94/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6046 - val_loss: 0.7117\n",
      "Epoch 95/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5978 - val_loss: 0.7121\n",
      "Epoch 96/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.6035 - val_loss: 0.7117\n",
      "Epoch 97/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6014 - val_loss: 0.7111\n",
      "Epoch 98/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5975 - val_loss: 0.7095\n",
      "Epoch 99/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.6002 - val_loss: 0.7073\n",
      "Epoch 100/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5973 - val_loss: 0.7064\n",
      "Epoch 101/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5987 - val_loss: 0.7060\n",
      "Epoch 102/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5963 - val_loss: 0.7059\n",
      "Epoch 103/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6037 - val_loss: 0.7050\n",
      "Epoch 104/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5949 - val_loss: 0.7051\n",
      "Epoch 105/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5964 - val_loss: 0.7044\n",
      "Epoch 106/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5990 - val_loss: 0.7032\n",
      "Epoch 107/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5981 - val_loss: 0.7032\n",
      "Epoch 108/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5979 - val_loss: 0.7038\n",
      "Epoch 109/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5951 - val_loss: 0.7030\n",
      "Epoch 110/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6012 - val_loss: 0.7012\n",
      "Epoch 111/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5981 - val_loss: 0.7003\n",
      "Epoch 112/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5947 - val_loss: 0.6999\n",
      "Epoch 113/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5930 - val_loss: 0.6990\n",
      "Epoch 114/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5960 - val_loss: 0.6975\n",
      "Epoch 115/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5985 - val_loss: 0.6966\n",
      "Epoch 116/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5947 - val_loss: 0.6963\n",
      "Epoch 117/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5960 - val_loss: 0.6966\n",
      "Epoch 118/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5954 - val_loss: 0.6957\n",
      "Epoch 119/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5956 - val_loss: 0.6946\n",
      "Epoch 120/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5929 - val_loss: 0.6944\n",
      "Epoch 121/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5944 - val_loss: 0.6942\n",
      "Epoch 122/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5933 - val_loss: 0.6929\n",
      "Epoch 123/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5929 - val_loss: 0.6925\n",
      "Epoch 124/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5975 - val_loss: 0.6919\n",
      "Epoch 125/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5973 - val_loss: 0.6913\n",
      "Epoch 126/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5957 - val_loss: 0.6901\n",
      "Epoch 127/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5941 - val_loss: 0.6901\n",
      "Epoch 128/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5939 - val_loss: 0.6912\n",
      "Epoch 129/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5925 - val_loss: 0.6910\n",
      "Epoch 130/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5911 - val_loss: 0.6902\n",
      "Epoch 131/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5910 - val_loss: 0.6884\n",
      "Epoch 132/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5918 - val_loss: 0.6881\n",
      "Epoch 133/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5951 - val_loss: 0.6864\n",
      "Epoch 134/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5917 - val_loss: 0.6857\n",
      "Epoch 135/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5903 - val_loss: 0.6852\n",
      "Epoch 136/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5967 - val_loss: 0.6838\n",
      "Epoch 137/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5869 - val_loss: 0.6847\n",
      "Epoch 138/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5934 - val_loss: 0.6853\n",
      "Epoch 139/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5910 - val_loss: 0.6853\n",
      "Epoch 140/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5915 - val_loss: 0.6838\n",
      "Epoch 141/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5892 - val_loss: 0.6827\n",
      "Epoch 142/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5917 - val_loss: 0.6815\n",
      "Epoch 143/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5905 - val_loss: 0.6805\n",
      "Epoch 144/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5896 - val_loss: 0.6796\n",
      "Epoch 145/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5925 - val_loss: 0.6797\n",
      "Epoch 146/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5925 - val_loss: 0.6795\n",
      "Epoch 147/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5947 - val_loss: 0.6786\n",
      "Epoch 148/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5905 - val_loss: 0.6766\n",
      "Epoch 149/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5881 - val_loss: 0.6768\n",
      "Epoch 150/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5888 - val_loss: 0.6765\n",
      "Epoch 151/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5897 - val_loss: 0.6753\n",
      "Epoch 152/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5886 - val_loss: 0.6746\n",
      "Epoch 153/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5905 - val_loss: 0.6740\n",
      "Epoch 154/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5894 - val_loss: 0.6729\n",
      "Epoch 155/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5874 - val_loss: 0.6724\n",
      "Epoch 156/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5924 - val_loss: 0.6698\n",
      "Epoch 157/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5902 - val_loss: 0.6692\n",
      "Epoch 158/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5874 - val_loss: 0.6690\n",
      "Epoch 159/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5864 - val_loss: 0.6673\n",
      "Epoch 160/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5930 - val_loss: 0.6660\n",
      "Epoch 161/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5906 - val_loss: 0.6680\n",
      "Epoch 162/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5862 - val_loss: 0.6654\n",
      "Epoch 163/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5851 - val_loss: 0.6612\n",
      "Epoch 164/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5860 - val_loss: 0.6596\n",
      "Epoch 165/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5881 - val_loss: 0.6607\n",
      "Epoch 166/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5842 - val_loss: 0.6600\n",
      "Epoch 167/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5835 - val_loss: 0.6577\n",
      "Epoch 168/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5852 - val_loss: 0.6549\n",
      "Epoch 169/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5811 - val_loss: 0.6538\n",
      "Epoch 170/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5835 - val_loss: 0.6523\n",
      "Epoch 171/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5853 - val_loss: 0.6519\n",
      "Epoch 172/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5772 - val_loss: 0.6482\n",
      "Epoch 173/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5849 - val_loss: 0.6461\n",
      "Epoch 174/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5818 - val_loss: 0.6489\n",
      "Epoch 175/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5814 - val_loss: 0.6434\n",
      "Epoch 176/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5846 - val_loss: 0.6422\n",
      "Epoch 177/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5811 - val_loss: 0.6471\n",
      "Epoch 178/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5878 - val_loss: 0.6413\n",
      "Epoch 179/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5830 - val_loss: 0.6435\n",
      "Epoch 180/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5832 - val_loss: 0.6421\n",
      "Epoch 181/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5826 - val_loss: 0.6425\n",
      "Epoch 182/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5811 - val_loss: 0.6414\n",
      "Epoch 183/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5809 - val_loss: 0.6391\n",
      "Epoch 184/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5821 - val_loss: 0.6413\n",
      "Epoch 185/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5799 - val_loss: 0.6393\n",
      "Epoch 186/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5788 - val_loss: 0.6382\n",
      "Epoch 187/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5805 - val_loss: 0.6370\n",
      "Epoch 188/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5816 - val_loss: 0.6377\n",
      "Epoch 189/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5793 - val_loss: 0.6363\n",
      "Epoch 190/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5827 - val_loss: 0.6356\n",
      "Epoch 191/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5792 - val_loss: 0.6371\n",
      "Epoch 192/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5800 - val_loss: 0.6338\n",
      "Epoch 193/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5827 - val_loss: 0.6333\n",
      "Epoch 194/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5786 - val_loss: 0.6349\n",
      "Epoch 195/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5844 - val_loss: 0.6314\n",
      "Epoch 196/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5749 - val_loss: 0.6339\n",
      "Epoch 197/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5781 - val_loss: 0.6299\n",
      "Epoch 198/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5788 - val_loss: 0.6316\n",
      "Epoch 199/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5782 - val_loss: 0.6298\n",
      "Epoch 200/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5797 - val_loss: 0.6275\n",
      "Epoch 201/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5760 - val_loss: 0.6312\n",
      "Epoch 202/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5776 - val_loss: 0.6297\n",
      "Epoch 203/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5775 - val_loss: 0.6240\n",
      "Epoch 204/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5808 - val_loss: 0.6274\n",
      "Epoch 205/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5751 - val_loss: 0.6279\n",
      "Epoch 206/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5775 - val_loss: 0.6249\n",
      "Epoch 207/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5789 - val_loss: 0.6235\n",
      "Epoch 208/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5782 - val_loss: 0.6251\n",
      "Epoch 209/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5801 - val_loss: 0.6231\n",
      "Epoch 210/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5788 - val_loss: 0.6242\n",
      "Epoch 211/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5798 - val_loss: 0.6220\n",
      "Epoch 212/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5764 - val_loss: 0.6226\n",
      "Epoch 213/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5755 - val_loss: 0.6217\n",
      "Epoch 214/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5781 - val_loss: 0.6207\n",
      "Epoch 215/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5811 - val_loss: 0.6210\n",
      "Epoch 216/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5746 - val_loss: 0.6227\n",
      "Epoch 217/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5777 - val_loss: 0.6175\n",
      "Epoch 218/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5766 - val_loss: 0.6194\n",
      "Epoch 219/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5776 - val_loss: 0.6193\n",
      "Epoch 220/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5736 - val_loss: 0.6179\n",
      "Epoch 221/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5742 - val_loss: 0.6133\n",
      "Epoch 222/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5774 - val_loss: 0.6170\n",
      "Epoch 223/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5779 - val_loss: 0.6178\n",
      "Epoch 224/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.5751 - val_loss: 0.6140\n",
      "Epoch 225/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5743 - val_loss: 0.6136\n",
      "Epoch 226/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5801 - val_loss: 0.6136\n",
      "Epoch 227/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5751 - val_loss: 0.6162\n",
      "Epoch 228/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5757 - val_loss: 0.6125\n",
      "Epoch 229/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5753 - val_loss: 0.6104\n",
      "Epoch 230/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5749 - val_loss: 0.6130\n",
      "Epoch 231/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5757 - val_loss: 0.6113\n",
      "Epoch 232/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5746 - val_loss: 0.6108\n",
      "Epoch 233/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5745 - val_loss: 0.6111\n",
      "Epoch 234/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5761 - val_loss: 0.6087\n",
      "Epoch 235/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5750 - val_loss: 0.6112\n",
      "Epoch 236/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5746 - val_loss: 0.6093\n",
      "Epoch 237/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5742 - val_loss: 0.6087\n",
      "Epoch 238/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5713 - val_loss: 0.6065\n",
      "Epoch 239/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5757 - val_loss: 0.6070\n",
      "Epoch 240/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5716 - val_loss: 0.6105\n",
      "Epoch 241/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5766 - val_loss: 0.6044\n",
      "Epoch 242/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5760 - val_loss: 0.6053\n",
      "Epoch 243/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5729 - val_loss: 0.6084\n",
      "Epoch 244/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5755 - val_loss: 0.6033\n",
      "Epoch 245/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5736 - val_loss: 0.6035\n",
      "Epoch 246/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5764 - val_loss: 0.6049\n",
      "Epoch 247/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5740 - val_loss: 0.6056\n",
      "Epoch 248/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5714 - val_loss: 0.6025\n",
      "Epoch 249/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5717 - val_loss: 0.6009\n",
      "Epoch 250/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5725 - val_loss: 0.6045\n",
      "Epoch 251/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5714 - val_loss: 0.6022\n",
      "Epoch 252/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5700 - val_loss: 0.5995\n",
      "Epoch 253/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5697 - val_loss: 0.6006\n",
      "Epoch 254/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5721 - val_loss: 0.5997\n",
      "Epoch 255/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5750 - val_loss: 0.6013\n",
      "Epoch 256/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5717 - val_loss: 0.5994\n",
      "Epoch 257/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5709 - val_loss: 0.5994\n",
      "Epoch 258/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5730 - val_loss: 0.5987\n",
      "Epoch 259/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5741 - val_loss: 0.5985\n",
      "Epoch 260/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5776 - val_loss: 0.5982\n",
      "Epoch 261/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5732 - val_loss: 0.5960\n",
      "Epoch 262/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5750 - val_loss: 0.5979\n",
      "Epoch 263/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5700 - val_loss: 0.5998\n",
      "Epoch 264/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5724 - val_loss: 0.5928\n",
      "Epoch 265/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5690 - val_loss: 0.5964\n",
      "Epoch 266/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5709 - val_loss: 0.5950\n",
      "Epoch 267/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5691 - val_loss: 0.5937\n",
      "Epoch 268/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5703 - val_loss: 0.5943\n",
      "Epoch 269/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5702 - val_loss: 0.5929\n",
      "Epoch 270/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5723 - val_loss: 0.5937\n",
      "Epoch 271/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5696 - val_loss: 0.5925\n",
      "Epoch 272/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5697 - val_loss: 0.5913\n",
      "Epoch 273/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5713 - val_loss: 0.5915\n",
      "Epoch 274/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5686 - val_loss: 0.5921\n",
      "Epoch 275/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5708 - val_loss: 0.5905\n",
      "Epoch 276/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5730 - val_loss: 0.5906\n",
      "Epoch 277/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5676 - val_loss: 0.5917\n",
      "Epoch 278/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5697 - val_loss: 0.5873\n",
      "Epoch 279/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5716 - val_loss: 0.5898\n",
      "Epoch 280/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5726 - val_loss: 0.5912\n",
      "Epoch 281/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5722 - val_loss: 0.5893\n",
      "Epoch 282/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5709 - val_loss: 0.5864\n",
      "Epoch 283/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5693 - val_loss: 0.5909\n",
      "Epoch 284/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5686 - val_loss: 0.5889\n",
      "Epoch 285/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5697 - val_loss: 0.5862\n",
      "Epoch 286/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5689 - val_loss: 0.5864\n",
      "Epoch 287/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5729 - val_loss: 0.5873\n",
      "Epoch 288/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5674 - val_loss: 0.5904\n",
      "Epoch 289/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5720 - val_loss: 0.5847\n",
      "Epoch 290/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5709 - val_loss: 0.5843\n",
      "Epoch 291/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5706 - val_loss: 0.5863\n",
      "Epoch 292/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5671 - val_loss: 0.5835\n",
      "Epoch 293/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5693 - val_loss: 0.5782\n",
      "Epoch 294/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5673 - val_loss: 0.5824\n",
      "Epoch 295/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5668 - val_loss: 0.5811\n",
      "Epoch 296/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5689 - val_loss: 0.5780\n",
      "Epoch 297/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5683 - val_loss: 0.5796\n",
      "Epoch 298/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5688 - val_loss: 0.5788\n",
      "Epoch 299/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5659 - val_loss: 0.5789\n",
      "Epoch 300/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5702 - val_loss: 0.5773\n",
      "Epoch 301/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5674 - val_loss: 0.5782\n",
      "Epoch 302/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5698 - val_loss: 0.5784\n",
      "Epoch 303/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5659 - val_loss: 0.5776\n",
      "Epoch 304/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5692 - val_loss: 0.5756\n",
      "Epoch 305/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5659 - val_loss: 0.5786\n",
      "Epoch 306/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5672 - val_loss: 0.5743\n",
      "Epoch 307/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5688 - val_loss: 0.5759\n",
      "Epoch 308/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5714 - val_loss: 0.5763\n",
      "Epoch 309/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5672 - val_loss: 0.5743\n",
      "Epoch 310/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5679 - val_loss: 0.5747\n",
      "Epoch 311/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5672 - val_loss: 0.5744\n",
      "Epoch 312/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5672 - val_loss: 0.5748\n",
      "Epoch 313/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5691 - val_loss: 0.5733\n",
      "Epoch 314/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5685 - val_loss: 0.5741\n",
      "Epoch 315/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5647 - val_loss: 0.5715\n",
      "Epoch 316/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5653 - val_loss: 0.5744\n",
      "Epoch 317/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5670 - val_loss: 0.5707\n",
      "Epoch 318/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5684 - val_loss: 0.5729\n",
      "Epoch 319/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5677 - val_loss: 0.5738\n",
      "Epoch 320/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5686 - val_loss: 0.5696\n",
      "Epoch 321/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5703 - val_loss: 0.5735\n",
      "Epoch 322/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5642 - val_loss: 0.5732\n",
      "Epoch 323/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5675 - val_loss: 0.5679\n",
      "Epoch 324/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5654 - val_loss: 0.5705\n",
      "Epoch 325/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5650 - val_loss: 0.5715\n",
      "Epoch 326/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5669 - val_loss: 0.5676\n",
      "Epoch 327/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5664 - val_loss: 0.5690\n",
      "Epoch 328/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5653 - val_loss: 0.5704\n",
      "Epoch 329/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5668 - val_loss: 0.5693\n",
      "Epoch 330/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5649 - val_loss: 0.5661\n",
      "Epoch 331/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5647 - val_loss: 0.5696\n",
      "Epoch 332/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5673 - val_loss: 0.5692\n",
      "Epoch 333/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5665 - val_loss: 0.5669\n",
      "Epoch 334/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5648 - val_loss: 0.5694\n",
      "Epoch 335/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5657 - val_loss: 0.5680\n",
      "Epoch 336/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5667 - val_loss: 0.5667\n",
      "Epoch 337/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5644 - val_loss: 0.5693\n",
      "Epoch 338/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5646 - val_loss: 0.5653\n",
      "Epoch 339/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5650 - val_loss: 0.5670\n",
      "Epoch 340/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5645 - val_loss: 0.5663\n",
      "Epoch 341/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5671 - val_loss: 0.5636\n",
      "Epoch 342/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5672 - val_loss: 0.5688\n",
      "Epoch 343/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5681 - val_loss: 0.5697\n",
      "Epoch 344/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5664 - val_loss: 0.5620\n",
      "Epoch 345/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5658 - val_loss: 0.5659\n",
      "Epoch 346/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5679 - val_loss: 0.5680\n",
      "Epoch 347/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5655 - val_loss: 0.5650\n",
      "Epoch 348/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5651 - val_loss: 0.5639\n",
      "Epoch 349/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5635 - val_loss: 0.5669\n",
      "Epoch 350/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5633 - val_loss: 0.5652\n",
      "Epoch 351/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5671 - val_loss: 0.5645\n",
      "Epoch 352/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5656 - val_loss: 0.5674\n",
      "Epoch 353/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5638 - val_loss: 0.5675\n",
      "Epoch 354/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5644 - val_loss: 0.5617\n",
      "Epoch 355/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5625 - val_loss: 0.5658\n",
      "Epoch 356/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5663 - val_loss: 0.5660\n",
      "Epoch 357/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5608 - val_loss: 0.5634\n",
      "Epoch 358/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5650 - val_loss: 0.5630\n",
      "Epoch 359/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5665 - val_loss: 0.5657\n",
      "Epoch 360/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5612 - val_loss: 0.5636\n",
      "Epoch 361/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5644 - val_loss: 0.5608\n",
      "Epoch 362/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5624 - val_loss: 0.5671\n",
      "Epoch 363/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5642 - val_loss: 0.5592\n",
      "Epoch 364/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5641 - val_loss: 0.5623\n",
      "Epoch 365/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5636 - val_loss: 0.5642\n",
      "Epoch 366/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5640 - val_loss: 0.5578\n",
      "Epoch 367/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5637 - val_loss: 0.5639\n",
      "Epoch 368/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5642 - val_loss: 0.5622\n",
      "Epoch 369/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5610 - val_loss: 0.5573\n",
      "Epoch 370/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5638 - val_loss: 0.5625\n",
      "Epoch 371/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5582 - val_loss: 0.5608\n",
      "Epoch 372/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5613 - val_loss: 0.5581\n",
      "Epoch 373/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5615 - val_loss: 0.5598\n",
      "Epoch 374/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5624 - val_loss: 0.5608\n",
      "Epoch 375/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5594 - val_loss: 0.5600\n",
      "Epoch 376/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5600 - val_loss: 0.5588\n",
      "Epoch 377/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.5605 - val_loss: 0.5579\n",
      "Epoch 378/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5628 - val_loss: 0.5590\n",
      "Epoch 379/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5614 - val_loss: 0.5598\n",
      "Epoch 380/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5623 - val_loss: 0.5578\n",
      "Epoch 381/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5613 - val_loss: 0.5582\n",
      "Epoch 382/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5627 - val_loss: 0.5585\n",
      "Epoch 383/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5601 - val_loss: 0.5588\n",
      "Epoch 384/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5631 - val_loss: 0.5551\n",
      "Epoch 385/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5624 - val_loss: 0.5588\n",
      "Epoch 386/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5616 - val_loss: 0.5590\n",
      "Epoch 387/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5595 - val_loss: 0.5547\n",
      "Epoch 388/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5634 - val_loss: 0.5562\n",
      "Epoch 389/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5648 - val_loss: 0.5596\n",
      "Epoch 390/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.5603 - val_loss: 0.5568\n",
      "Epoch 391/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5592 - val_loss: 0.5524\n",
      "Epoch 392/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5608 - val_loss: 0.5605\n",
      "Epoch 393/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5614 - val_loss: 0.5540\n",
      "Epoch 394/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5617 - val_loss: 0.5544\n",
      "Epoch 395/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5608 - val_loss: 0.5557\n",
      "Epoch 396/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5607 - val_loss: 0.5553\n",
      "Epoch 397/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5604 - val_loss: 0.5553\n",
      "Epoch 398/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5623 - val_loss: 0.5537\n",
      "Epoch 399/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5627 - val_loss: 0.5555\n",
      "Epoch 400/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5591 - val_loss: 0.5528\n",
      "Epoch 401/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5607 - val_loss: 0.5514\n",
      "Epoch 402/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5596 - val_loss: 0.5571\n",
      "Epoch 403/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5598 - val_loss: 0.5519\n",
      "Epoch 404/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5598 - val_loss: 0.5517\n",
      "Epoch 405/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5580 - val_loss: 0.5546\n",
      "Epoch 406/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5589 - val_loss: 0.5519\n",
      "Epoch 407/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5628 - val_loss: 0.5514\n",
      "Epoch 408/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5615 - val_loss: 0.5531\n",
      "Epoch 409/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5585 - val_loss: 0.5531\n",
      "Epoch 410/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5643 - val_loss: 0.5517\n",
      "Epoch 411/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5600 - val_loss: 0.5531\n",
      "Epoch 412/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5601 - val_loss: 0.5507\n",
      "Epoch 413/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5610 - val_loss: 0.5516\n",
      "Epoch 414/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5597 - val_loss: 0.5546\n",
      "Epoch 415/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5595 - val_loss: 0.5490\n",
      "Epoch 416/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5590 - val_loss: 0.5515\n",
      "Epoch 417/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5586 - val_loss: 0.5523\n",
      "Epoch 418/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5576 - val_loss: 0.5478\n",
      "Epoch 419/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5611 - val_loss: 0.5538\n",
      "Epoch 420/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5608 - val_loss: 0.5488\n",
      "Epoch 421/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5544 - val_loss: 0.5484\n",
      "Epoch 422/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5586 - val_loss: 0.5503\n",
      "Epoch 423/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5587 - val_loss: 0.5512\n",
      "Epoch 424/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5613 - val_loss: 0.5459\n",
      "Epoch 425/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5610 - val_loss: 0.5538\n",
      "Epoch 426/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5586 - val_loss: 0.5471\n",
      "Epoch 427/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5599 - val_loss: 0.5471\n",
      "Epoch 428/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5596 - val_loss: 0.5495\n",
      "Epoch 429/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5553 - val_loss: 0.5495\n",
      "Epoch 430/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5576 - val_loss: 0.5450\n",
      "Epoch 431/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5590 - val_loss: 0.5498\n",
      "Epoch 432/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5613 - val_loss: 0.5471\n",
      "Epoch 433/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5572 - val_loss: 0.5477\n",
      "Epoch 434/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5594 - val_loss: 0.5458\n",
      "Epoch 435/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5577 - val_loss: 0.5504\n",
      "Epoch 436/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.5583 - val_loss: 0.5460\n",
      "Epoch 437/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5578 - val_loss: 0.5465\n",
      "Epoch 438/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5601 - val_loss: 0.5469\n",
      "Epoch 439/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5601 - val_loss: 0.5476\n",
      "Epoch 440/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5609 - val_loss: 0.5464\n",
      "Epoch 441/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5576 - val_loss: 0.5480\n",
      "Epoch 442/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5537 - val_loss: 0.5443\n",
      "Epoch 443/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5647 - val_loss: 0.5467\n",
      "Epoch 444/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5575 - val_loss: 0.5520\n",
      "Epoch 445/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5569 - val_loss: 0.5425\n",
      "Epoch 446/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5582 - val_loss: 0.5457\n",
      "Epoch 447/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5585 - val_loss: 0.5496\n",
      "Epoch 448/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5578 - val_loss: 0.5415\n",
      "Epoch 449/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5591 - val_loss: 0.5456\n",
      "Epoch 450/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5572 - val_loss: 0.5480\n",
      "Epoch 451/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5563 - val_loss: 0.5411\n",
      "Epoch 452/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5581 - val_loss: 0.5451\n",
      "Epoch 453/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5579 - val_loss: 0.5480\n",
      "Epoch 454/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5571 - val_loss: 0.5414\n",
      "Epoch 455/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5563 - val_loss: 0.5455\n",
      "Epoch 456/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5581 - val_loss: 0.5432\n",
      "Epoch 457/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5566 - val_loss: 0.5444\n",
      "Epoch 458/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5594 - val_loss: 0.5454\n",
      "Epoch 459/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5564 - val_loss: 0.5433\n",
      "Epoch 460/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5591 - val_loss: 0.5434\n",
      "Epoch 461/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5562 - val_loss: 0.5440\n",
      "Epoch 462/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5609 - val_loss: 0.5433\n",
      "Epoch 463/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5577 - val_loss: 0.5461\n",
      "Epoch 464/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5591 - val_loss: 0.5427\n",
      "Epoch 465/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5580 - val_loss: 0.5416\n",
      "Epoch 466/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5597 - val_loss: 0.5470\n",
      "Epoch 467/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5567 - val_loss: 0.5418\n",
      "Epoch 468/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5551 - val_loss: 0.5411\n",
      "Epoch 469/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5562 - val_loss: 0.5470\n",
      "Epoch 470/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5598 - val_loss: 0.5398\n",
      "Epoch 471/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5584 - val_loss: 0.5425\n",
      "Epoch 472/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5610 - val_loss: 0.5460\n",
      "Epoch 473/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5592 - val_loss: 0.5414\n",
      "Epoch 474/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5596 - val_loss: 0.5417\n",
      "Epoch 475/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5576 - val_loss: 0.5426\n",
      "Epoch 476/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5569 - val_loss: 0.5407\n",
      "Epoch 477/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5566 - val_loss: 0.5420\n",
      "Epoch 478/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5631 - val_loss: 0.5404\n",
      "Epoch 479/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5542 - val_loss: 0.5458\n",
      "Epoch 480/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5563 - val_loss: 0.5383\n",
      "Epoch 481/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5610 - val_loss: 0.5406\n",
      "Epoch 482/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5583 - val_loss: 0.5479\n",
      "Epoch 483/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5565 - val_loss: 0.5365\n",
      "Epoch 484/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5578 - val_loss: 0.5413\n",
      "Epoch 485/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.5588 - val_loss: 0.5426\n",
      "Epoch 486/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5581 - val_loss: 0.5391\n",
      "Epoch 487/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5576 - val_loss: 0.5415\n",
      "Epoch 488/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5564 - val_loss: 0.5386\n",
      "Epoch 489/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5563 - val_loss: 0.5407\n",
      "Epoch 490/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5574 - val_loss: 0.5391\n",
      "Epoch 491/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.5566 - val_loss: 0.5438\n",
      "Epoch 492/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5570 - val_loss: 0.5378\n",
      "Epoch 493/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5596 - val_loss: 0.5403\n",
      "Epoch 494/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5560 - val_loss: 0.5433\n",
      "Epoch 495/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5587 - val_loss: 0.5347\n",
      "Epoch 496/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.5594 - val_loss: 0.5437\n",
      "Epoch 497/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.5581 - val_loss: 0.5410\n",
      "Epoch 498/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.5558 - val_loss: 0.5366\n",
      "Epoch 499/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5575 - val_loss: 0.5404\n",
      "Epoch 500/500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5540 - val_loss: 0.5437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x346d35ac0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_under_train, y = y_under_train, validation_data= (X_test, y_test), epochs = 500, verbose = 1, batch_size = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0a90858-929a-4610-ab8e-9a6f8bffb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "814a6a4d-fb28-4fb3-a2f8-76cf507707c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832e7d12-8c5e-42bd-ae96-819af0685d7c",
   "metadata": {},
   "source": [
    "# Model Using Complete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f7a68230-92fa-4df8-8a88-2a56c27550ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complete = Sequential()\n",
    "model_complete.add(Dense(26, activation = 'relu'))\n",
    "model_complete.add(Dense(14, activation = 'relu'))\n",
    "model_complete.add(Dense(1, activation = 'sigmoid'))\n",
    "model_complete.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5df4105f-ec1c-465c-bf26-e32751d45e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 205.8320 - val_loss: 0.9169\n",
      "Epoch 2/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 25.7212 - val_loss: 2.8747\n",
      "Epoch 3/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 20.7508 - val_loss: 3.4751\n",
      "Epoch 4/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 18.2871 - val_loss: 1.0369\n",
      "Epoch 5/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 20.2129 - val_loss: 14.1774\n",
      "Epoch 6/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 21.4112 - val_loss: 19.7449\n",
      "Epoch 7/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 25.1089 - val_loss: 9.9505\n",
      "Epoch 8/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 21.6869 - val_loss: 7.8260\n",
      "Epoch 9/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 23.9947 - val_loss: 5.4889\n",
      "Epoch 10/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 18.1428 - val_loss: 6.1204\n",
      "Epoch 11/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 20.1898 - val_loss: 3.2297\n",
      "Epoch 12/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 14.7469 - val_loss: 1.4717\n",
      "Epoch 13/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 11.0405 - val_loss: 11.9736\n",
      "Epoch 14/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - loss: 20.3884 - val_loss: 5.4284\n",
      "Epoch 15/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 18.0315 - val_loss: 2.3179\n",
      "Epoch 16/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 17.2288 - val_loss: 3.3412\n",
      "Epoch 17/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 13.2998 - val_loss: 12.8251\n",
      "Epoch 18/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 16.2864 - val_loss: 1.5305\n",
      "Epoch 19/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 9.3765 - val_loss: 6.4419\n",
      "Epoch 20/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 7.4928 - val_loss: 1.7548\n",
      "Epoch 21/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 7.7567 - val_loss: 11.2949\n",
      "Epoch 22/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 13.8803 - val_loss: 4.4532\n",
      "Epoch 23/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - loss: 19.4791 - val_loss: 0.6307\n",
      "Epoch 24/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 13.2512 - val_loss: 7.9384\n",
      "Epoch 25/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - loss: 11.7807 - val_loss: 6.2295\n",
      "Epoch 26/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 12.5758 - val_loss: 5.4174\n",
      "Epoch 27/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 11.3157 - val_loss: 8.9440\n",
      "Epoch 28/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 10.2598 - val_loss: 6.7391\n",
      "Epoch 29/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 7.3313 - val_loss: 0.4000\n",
      "Epoch 30/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 1.3699 - val_loss: 4.9553\n",
      "Epoch 31/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 4.4477 - val_loss: 8.0796\n",
      "Epoch 32/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 11.5872 - val_loss: 3.4064\n",
      "Epoch 33/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 6.3898 - val_loss: 0.4778\n",
      "Epoch 34/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - loss: 2.0180 - val_loss: 2.0345\n",
      "Epoch 35/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 1.5390 - val_loss: 2.2259\n",
      "Epoch 36/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 3.9477 - val_loss: 3.8544\n",
      "Epoch 37/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 4.2438 - val_loss: 5.8509\n",
      "Epoch 38/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 6.7139 - val_loss: 1.4272\n",
      "Epoch 39/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 6.7648 - val_loss: 2.6865\n",
      "Epoch 40/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - loss: 2.1318 - val_loss: 3.3618\n",
      "Epoch 41/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 4.1185 - val_loss: 0.2293\n",
      "Epoch 42/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.8633 - val_loss: 0.6788\n",
      "Epoch 43/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 2.3846 - val_loss: 3.7818\n",
      "Epoch 44/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 4.8077 - val_loss: 1.1020\n",
      "Epoch 45/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2891 - val_loss: 0.1334\n",
      "Epoch 46/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - loss: 1.9513 - val_loss: 0.9997\n",
      "Epoch 47/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 1.4322 - val_loss: 0.4142\n",
      "Epoch 48/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.9881 - val_loss: 0.9204\n",
      "Epoch 49/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 4.4080 - val_loss: 1.7010\n",
      "Epoch 50/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 2.4169 - val_loss: 2.0680\n",
      "Epoch 51/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 2.2333 - val_loss: 0.4771\n",
      "Epoch 52/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 2.4409 - val_loss: 0.8174\n",
      "Epoch 53/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 1.2574 - val_loss: 0.1231\n",
      "Epoch 54/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - loss: 0.8483 - val_loss: 1.5756\n",
      "Epoch 55/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 982us/step - loss: 1.3156 - val_loss: 0.2755\n",
      "Epoch 56/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 0.3805 - val_loss: 0.1858\n",
      "Epoch 57/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 1.8259 - val_loss: 0.1964\n",
      "Epoch 58/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 3.6716 - val_loss: 2.6665\n",
      "Epoch 59/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 2.9198 - val_loss: 0.1192\n",
      "Epoch 60/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 1.6213 - val_loss: 0.2073\n",
      "Epoch 61/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - loss: 0.8944 - val_loss: 0.3128\n",
      "Epoch 62/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 2.8273 - val_loss: 0.0845\n",
      "Epoch 63/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 1.3430 - val_loss: 13.1677\n",
      "Epoch 64/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 1.8726 - val_loss: 0.2878\n",
      "Epoch 65/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 1.9705 - val_loss: 0.0901\n",
      "Epoch 66/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.6700 - val_loss: 0.1695\n",
      "Epoch 67/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.4801 - val_loss: 0.3021\n",
      "Epoch 68/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.2964 - val_loss: 0.0627\n",
      "Epoch 69/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - loss: 0.3426 - val_loss: 1.6179\n",
      "Epoch 70/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 1.5863 - val_loss: 0.0679\n",
      "Epoch 71/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.4800 - val_loss: 0.1885\n",
      "Epoch 72/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.2103 - val_loss: 0.3126\n",
      "Epoch 73/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.4277 - val_loss: 0.0457\n",
      "Epoch 74/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.2347 - val_loss: 0.0244\n",
      "Epoch 75/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.1887 - val_loss: 0.3350\n",
      "Epoch 76/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.3690 - val_loss: 0.0498\n",
      "Epoch 77/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.2102 - val_loss: 0.0210\n",
      "Epoch 78/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - loss: 0.0733 - val_loss: 0.0215\n",
      "Epoch 79/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - loss: 0.0868 - val_loss: 0.0190\n",
      "Epoch 80/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - loss: 0.0471 - val_loss: 0.0173\n",
      "Epoch 81/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - loss: 0.0410 - val_loss: 0.0197\n",
      "Epoch 82/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0651 - val_loss: 0.0182\n",
      "Epoch 83/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - loss: 0.0396 - val_loss: 0.0169\n",
      "Epoch 84/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0393 - val_loss: 0.0218\n",
      "Epoch 85/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0310 - val_loss: 0.0177\n",
      "Epoch 86/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0303 - val_loss: 0.7593\n",
      "Epoch 87/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - loss: 0.7256 - val_loss: 0.0420\n",
      "Epoch 88/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.0659 - val_loss: 0.0230\n",
      "Epoch 89/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 962us/step - loss: 0.0905 - val_loss: 0.0222\n",
      "Epoch 90/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - loss: 0.0315 - val_loss: 0.0287\n",
      "Epoch 91/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0512 - val_loss: 0.0183\n",
      "Epoch 92/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0346 - val_loss: 0.0166\n",
      "Epoch 93/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0282 - val_loss: 0.0402\n",
      "Epoch 94/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0380 - val_loss: 0.0174\n",
      "Epoch 95/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - loss: 0.0233 - val_loss: 0.0168\n",
      "Epoch 96/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0432 - val_loss: 0.1742\n",
      "Epoch 97/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.1550 - val_loss: 0.0213\n",
      "Epoch 98/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0291 - val_loss: 0.0192\n",
      "Epoch 99/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0270 - val_loss: 0.0185\n",
      "Epoch 100/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - loss: 0.0269 - val_loss: 0.0219\n",
      "Epoch 101/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0286 - val_loss: 0.0178\n",
      "Epoch 102/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - loss: 0.0283 - val_loss: 0.0172\n",
      "Epoch 103/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0287 - val_loss: 0.0173\n",
      "Epoch 104/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - loss: 0.0231 - val_loss: 0.0214\n",
      "Epoch 105/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - loss: 0.0254 - val_loss: 0.0160\n",
      "Epoch 106/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0226 - val_loss: 0.0161\n",
      "Epoch 107/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - loss: 0.0220 - val_loss: 0.0215\n",
      "Epoch 108/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - loss: 0.0231 - val_loss: 0.0164\n",
      "Epoch 109/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0228 - val_loss: 0.0158\n",
      "Epoch 110/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0218 - val_loss: 0.1523\n",
      "Epoch 111/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.4777 - val_loss: 0.0189\n",
      "Epoch 112/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - loss: 0.0954 - val_loss: 0.0239\n",
      "Epoch 113/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - loss: 0.0254 - val_loss: 0.0149\n",
      "Epoch 114/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - loss: 0.0204 - val_loss: 0.0150\n",
      "Epoch 115/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 116/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - loss: 0.0199 - val_loss: 0.0151\n",
      "Epoch 117/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0196 - val_loss: 0.0139\n",
      "Epoch 118/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - loss: 0.0198 - val_loss: 0.0137\n",
      "Epoch 119/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - loss: 0.0192 - val_loss: 0.0141\n",
      "Epoch 120/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0195 - val_loss: 0.0173\n",
      "Epoch 121/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.0196 - val_loss: 0.0136\n",
      "Epoch 122/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0185 - val_loss: 0.0143\n",
      "Epoch 123/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0192 - val_loss: 0.0135\n",
      "Epoch 124/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - loss: 0.0324 - val_loss: 0.0144\n",
      "Epoch 125/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - loss: 0.0196 - val_loss: 0.0175\n",
      "Epoch 126/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0190 - val_loss: 0.0131\n",
      "Epoch 127/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - loss: 0.0187 - val_loss: 0.0158\n",
      "Epoch 128/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0189 - val_loss: 0.0158\n",
      "Epoch 129/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - loss: 0.0189 - val_loss: 0.0133\n",
      "Epoch 130/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 0.0178 - val_loss: 0.0129\n",
      "Epoch 131/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - loss: 0.0184 - val_loss: 0.0135\n",
      "Epoch 132/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0181 - val_loss: 0.0128\n",
      "Epoch 133/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0188 - val_loss: 0.0127\n",
      "Epoch 134/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - loss: 0.0179 - val_loss: 0.0122\n",
      "Epoch 135/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - loss: 0.0235 - val_loss: 0.0284\n",
      "Epoch 136/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - loss: 0.0919 - val_loss: 0.1278\n",
      "Epoch 137/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.1102 - val_loss: 0.2110\n",
      "Epoch 138/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1676 - val_loss: 0.0187\n",
      "Epoch 139/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0260 - val_loss: 0.0348\n",
      "Epoch 140/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0266 - val_loss: 0.0166\n",
      "Epoch 141/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0230 - val_loss: 0.0164\n",
      "Epoch 142/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0223 - val_loss: 0.0154\n",
      "Epoch 143/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - loss: 0.0326 - val_loss: 0.0150\n",
      "Epoch 144/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0229 - val_loss: 0.0151\n",
      "Epoch 145/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0265 - val_loss: 0.0145\n",
      "Epoch 146/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0190 - val_loss: 0.0135\n",
      "Epoch 147/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0224 - val_loss: 0.0133\n",
      "Epoch 148/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0188 - val_loss: 0.0134\n",
      "Epoch 149/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0182 - val_loss: 0.0129\n",
      "Epoch 150/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - loss: 0.0189 - val_loss: 0.0143\n",
      "Epoch 151/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - loss: 0.0203 - val_loss: 0.0166\n",
      "Epoch 152/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0219 - val_loss: 0.0148\n",
      "Epoch 153/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - loss: 0.0212 - val_loss: 0.0148\n",
      "Epoch 154/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - loss: 0.0193 - val_loss: 0.0141\n",
      "Epoch 155/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0186 - val_loss: 0.0130\n",
      "Epoch 156/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - loss: 0.0175 - val_loss: 0.0147\n",
      "Epoch 157/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - loss: 0.0182 - val_loss: 0.0133\n",
      "Epoch 158/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 949us/step - loss: 0.0189 - val_loss: 0.0124\n",
      "Epoch 159/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - loss: 0.0184 - val_loss: 0.0124\n",
      "Epoch 160/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0174 - val_loss: 0.0128\n",
      "Epoch 161/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - loss: 0.0173 - val_loss: 0.0132\n",
      "Epoch 162/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - loss: 0.0177 - val_loss: 0.0125\n",
      "Epoch 163/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - loss: 0.0169 - val_loss: 0.0122\n",
      "Epoch 164/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 165/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0171 - val_loss: 0.0123\n",
      "Epoch 166/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0174 - val_loss: 0.0142\n",
      "Epoch 167/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0173 - val_loss: 0.0138\n",
      "Epoch 168/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - loss: 0.0172 - val_loss: 0.0120\n",
      "Epoch 169/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 170/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - loss: 0.0159 - val_loss: 0.0120\n",
      "Epoch 171/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0173 - val_loss: 0.0115\n",
      "Epoch 172/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - loss: 0.0168 - val_loss: 0.0127\n",
      "Epoch 173/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0165 - val_loss: 0.0123\n",
      "Epoch 174/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0161 - val_loss: 0.0114\n",
      "Epoch 175/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0168 - val_loss: 0.0114\n",
      "Epoch 176/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - loss: 0.0167 - val_loss: 0.0168\n",
      "Epoch 177/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 178/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - loss: 0.0179 - val_loss: 0.0145\n",
      "Epoch 179/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - loss: 0.0175 - val_loss: 0.0125\n",
      "Epoch 180/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - loss: 0.0169 - val_loss: 0.0129\n",
      "Epoch 181/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 182/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0182 - val_loss: 0.0127\n",
      "Epoch 183/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - loss: 0.0162 - val_loss: 0.0114\n",
      "Epoch 184/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - loss: 0.0159 - val_loss: 0.0146\n",
      "Epoch 185/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0160 - val_loss: 0.0135\n",
      "Epoch 186/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0162 - val_loss: 0.0126\n",
      "Epoch 187/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - loss: 0.0162 - val_loss: 0.0125\n",
      "Epoch 188/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.0156 - val_loss: 0.0124\n",
      "Epoch 189/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0158 - val_loss: 0.0113\n",
      "Epoch 190/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - loss: 0.0245 - val_loss: 0.0176\n",
      "Epoch 191/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0277 - val_loss: 0.0137\n",
      "Epoch 192/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - loss: 0.0171 - val_loss: 0.0126\n",
      "Epoch 193/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 936us/step - loss: 0.0168 - val_loss: 0.0116\n",
      "Epoch 194/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - loss: 0.0161 - val_loss: 0.0152\n",
      "Epoch 195/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - loss: 0.0166 - val_loss: 0.0116\n",
      "Epoch 196/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - loss: 0.0165 - val_loss: 0.0128\n",
      "Epoch 197/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - loss: 0.0160 - val_loss: 0.0115\n",
      "Epoch 198/500\n",
      "\u001b[1m325/325\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - loss: 0.0168 - val_loss: 0.0149\n",
      "Epoch 199/500\n",
      "\u001b[1m130/325\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 782us/step - loss: 0.0158"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_complete\u001b[38;5;241m.\u001b[39mfit(x \u001b[38;5;241m=\u001b[39m X_train, y \u001b[38;5;241m=\u001b[39m y_train, validation_data\u001b[38;5;241m=\u001b[39m (X_test, y_test), epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4000\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    321\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1558\u001b[0m   )\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_complete.fit(x = X_train, y = y_train, validation_data= (X_test, y_test), epochs = 500, verbose = 1, batch_size = 4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8240d3-f70a-4fe3-9fec-e2c99312dbe4",
   "metadata": {},
   "source": [
    "### As we can see that while using complete un-undersampled data, the validation data and the loss are both very low, but that is owning to the fact that the majority of data points in both data sets are those corresponding to \"NON-FRAUD\". Hence, to truly test the validity of these models we need to test them on data sets where both \"Fraud\" and \"Non-Fraud\" data points are in comparable ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b38eb0c-2662-4bb9-a434-63bb6516e71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled class distribution: Counter({0: 2145, 1: 2145})\n"
     ]
    }
   ],
   "source": [
    "X_under_test, y_under_test = undersample.fit_resample(X_test, y_test)\n",
    "print(\"Undersampled class distribution:\", Counter(y_under_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ad72a1f-0cb7-45c1-aed4-7aa5def58010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287us/step\n"
     ]
    }
   ],
   "source": [
    "prediction_model = model.predict(X_under_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "81705a71-224c-41a2-a1de-5fb0f946f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m135/135\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271us/step\n"
     ]
    }
   ],
   "source": [
    "prediction_model_complete = model_complete.predict(X_under_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c901fa6c-ed2d-4068-af51-cf17bd01c3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b49d845-2ef4-4646-82db-0072cacbec29",
   "metadata": {},
   "source": [
    "#### Metrics of model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "43d455ee-6fe8-4b9d-9213-52e8edbc97ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38645667],\n",
       "       [0.38645667],\n",
       "       [0.38645667],\n",
       "       ...,\n",
       "       [0.38645667],\n",
       "       [0.38645676],\n",
       "       [0.38645676]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bebe5d33-3622-41c0-85a0-2018cc89af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_model1 = []\n",
    "for i in range(len(prediction_model)):\n",
    "    if prediction_model[i][0] > 0.5:\n",
    "        prediction_model[i][0] = int(1)\n",
    "        predictions_model1.append(prediction_model[i][0]) \n",
    "    else:\n",
    "        prediction_model[i][0] = int(0)\n",
    "        predictions_model1.append(prediction_model[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "75d3d377-5ab8-4b83-87ae-828a4993b0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.75      2145\n",
      "           1       0.96      0.37      0.54      2145\n",
      "\n",
      "    accuracy                           0.68      4290\n",
      "   macro avg       0.78      0.68      0.65      4290\n",
      "weighted avg       0.78      0.68      0.65      4290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_under_test, predictions_model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9d9861f9-4d9f-44ac-92b1-c3c366f0ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2108   37]\n",
      " [1344  801]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_under_test, predictions_model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51be320-f954-4df2-9ae0-1871527e4667",
   "metadata": {},
   "source": [
    "#### Metrics of Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b8a336df-754e-40c3-873c-9a699e497762",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_model2 = []\n",
    "for i in range(len(prediction_model_complete)):\n",
    "    if prediction_model_complete[i][0] > 0.5:\n",
    "        prediction_model_complete[i][0] = int(1)\n",
    "        predictions_model2.append(prediction_model_complete[i][0]) \n",
    "    else:\n",
    "        prediction_model_complete[i][0] = int(0)\n",
    "        predictions_model2.append(prediction_model_complete[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4914249e-58eb-42ae-aa51-c1959526a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80      2145\n",
      "           1       1.00      0.49      0.65      2145\n",
      "\n",
      "    accuracy                           0.74      4290\n",
      "   macro avg       0.83      0.74      0.72      4290\n",
      "weighted avg       0.83      0.74      0.72      4290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_under_test, predictions_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f861f3e-ef1d-4390-81da-fe9ddd1267be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2144    1]\n",
      " [1102 1043]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_under_test, predictions_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45084ce2-dca9-4112-8548-52859630a02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
